{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2Model, pipeline, AutoModelForCausalLM, \\\n",
    "AutoTokenizer, BitsAndBytesConfig, LlamaTokenizer, LlamaModel, AutoModelForTextEncoding\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import RobertaModel, RobertaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 1024\n",
      "2278 2278 2278 2278\n"
     ]
    }
   ],
   "source": [
    "human_bert = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/BERT/human_embeddings.npy', allow_pickle=True)\n",
    "human_gpt = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/FLAN/human_embeddings.npy', allow_pickle=True)\n",
    "\n",
    "ai_bert = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/BERT/gpt_embeddings.npy', allow_pickle=True)\n",
    "ai_gpt = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/FLAN/gpt_embeddings.npy', allow_pickle=True)\n",
    "ai_embed_length = len(ai_gpt[0])\n",
    "print(ai_embed_length, len(ai_bert[0][0]))\n",
    "bert_min_length = min(len(human_bert), len(ai_bert))\n",
    "human_bert = human_bert[:bert_min_length]\n",
    "ai_bert = ai_bert[:bert_min_length]\n",
    "\n",
    "gpt_min_length = min(len(human_gpt), len(ai_gpt))\n",
    "human_gpt = human_gpt[:bert_min_length]\n",
    "ai_gpt = ai_gpt[:bert_min_length]\n",
    "\n",
    "print(len(human_bert), len(human_gpt), len(ai_bert), len(ai_gpt))\n",
    "\n",
    "human_bert = list(human_bert)\n",
    "ai_bert = list(ai_bert)\n",
    "human_gpt = list(human_gpt)\n",
    "ai_gpt = list(ai_gpt)\n",
    "\n",
    "human_bert = torch.tensor(human_bert)\n",
    "ai_bert = torch.tensor(ai_bert)\n",
    "human_gpt = torch.tensor(human_gpt).reshape([bert_min_length, 1, ai_embed_length])\n",
    "ai_gpt = torch.tensor(ai_gpt).reshape([bert_min_length, 1, ai_embed_length])\n",
    "\n",
    "# Display the result tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2278, 1, 1024]) torch.Size([2278, 1, 1024]) torch.Size([2278, 1, 4096]) torch.Size([2278, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(human_bert.shape, ai_bert.shape, human_gpt.shape, ai_gpt.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = torch.cat([human_bert, human_gpt], dim = 2).view(2278, 64, 80)\n",
    "ai = torch.cat([ai_bert, ai_gpt], dim = 2).view(2278, 64, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4556, 64, 80])\n"
     ]
    }
   ],
   "source": [
    "embeds = torch.cat((human, ai), dim=0)\n",
    "\n",
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = embeds.view(4556,64, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4556, 64, 80])\n"
     ]
    }
   ],
   "source": [
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_tensor = torch.zeros((bert_min_length))\n",
    "ones_tensor = torch.ones((bert_min_length))\n",
    "\n",
    "labels = torch.cat((zeros_tensor, ones_tensor), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4556\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test_size = 0.2\n",
    "dataset = TensorDataset(embeds, labels)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=test_size, random_state=42)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Create DataLoader for training set\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class GPT_CNN2D(nn.Module):\n",
    "    def __init__(self, embedding_model):\n",
    "        super(GPT_CNN2D, self).__init__()\n",
    "        self.em_model = embedding_model\n",
    "        \n",
    "            \n",
    "        if embedding_model == \"custom\":\n",
    "            self.conv1 = nn.Conv2d(1, 128, kernel_size=8, padding=1, stride = 2)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv2 = nn.Conv2d(128, 64, kernel_size=5, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.flatten = nn.Flatten()            \n",
    "            # self.fc1 = nn.Linear(96, 2)\n",
    "            self.fc1 = nn.Linear(384, 2)\n",
    "            # self.fc2 = nn.Linear(128, 2)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.em_model == \"custom\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.flatten(x)\n",
    "            # x = self.relu(self.fc1(x))\n",
    "            x = self.fc1(x)\n",
    "            # x = self.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GPT_CNN2D(embedding_model = \"custom\").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "# Create an instance of the model\n",
    "# Map the location to the first CUDA device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_weights = torch.load('/home/csgrad/kaushik3/LLM/Code/Embedding_Fusion/Code/gpt_BERT_FLAN.pth', map_location=device)\n",
    "model.load_state_dict(pretrained_weights)\n",
    "\n",
    "\n",
    "# Now the model is loaded with the pretrained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n",
      "Validation Accuracy: 0.5092\n",
      "TP: 102, FP: 60, TN: 2218, FN: 2176\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model = GPT_CNN2D(embedding_model = \"fusion3\").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "max_val_accuracy = 0\n",
    "# Step 5: Training Loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in total_dataset:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            #inputs = inputs.view(1,1,256,64,80)\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            TP += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            FP += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            TN += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "            FN += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "            total += labels.size(0)\n",
    "            #print(labels, predicted)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = correct / total\n",
    "    if max_val_accuracy<val_accuracy:\n",
    "        max_TP = TP\n",
    "        max_FP = FP\n",
    "        max_TN = TN\n",
    "        max_FN = FN\n",
    "    max_val_accuracy = max(max_val_accuracy, val_accuracy)\n",
    "    \n",
    "    \n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
