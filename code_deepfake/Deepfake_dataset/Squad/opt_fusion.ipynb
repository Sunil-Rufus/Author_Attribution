{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2Model, pipeline, AutoModelForCausalLM, \\\n",
    "AutoTokenizer, BitsAndBytesConfig, LlamaTokenizer, LlamaModel, AutoModelForTextEncoding\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import RobertaModel, RobertaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_bert = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/BERT/human_embeddings.npy', allow_pickle=True)\n",
    "human_gpt = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/GPT/human_embeddings.npy', allow_pickle=True)\n",
    "human_flan = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/FLAN/human_embeddings.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "ai_bert = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/BERT/opt_embeddings.npy', allow_pickle=True)\n",
    "ai_gpt = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/GPT/opt_embeddings.npy', allow_pickle=True)\n",
    "ai_flan = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/code.old/Deepfake_dataset/Squad/FLAN/opt_embeddings.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278 2278 2278 2278 2278 2278\n"
     ]
    }
   ],
   "source": [
    "\"\"\"human_bert = human_bert[:len(ai_bert)]\n",
    "human_gpt = human_gpt[:len(ai_gpt)]\n",
    "human_flan = human_flan[:len(ai_flan)]\"\"\"\n",
    "\n",
    "bert_min_length = min(len(human_bert), len(ai_bert))\n",
    "human_bert = human_bert[:bert_min_length]\n",
    "ai_bert = ai_bert[:bert_min_length]\n",
    "\n",
    "gpt_min_length = min(len(human_gpt), len(ai_gpt))\n",
    "human_gpt = human_gpt[:bert_min_length]\n",
    "ai_gpt = ai_gpt[:bert_min_length]\n",
    "\n",
    "flan_min_length = min(len(human_flan), len(ai_flan))\n",
    "human_flan = human_flan[:bert_min_length]\n",
    "ai_flan = ai_flan[:bert_min_length]\n",
    "\n",
    "\n",
    "print(len(human_bert), len(human_gpt), len(human_flan), len(ai_bert), len(ai_gpt), len(ai_flan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_bert = list(human_bert)\n",
    "ai_bert = list(ai_bert)\n",
    "human_gpt = list(human_gpt)\n",
    "ai_gpt = list(ai_gpt)\n",
    "human_flan = list(human_flan)\n",
    "ai_flan = list(ai_flan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518079/3416831968.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  human_bert = torch.tensor(human_bert)\n"
     ]
    }
   ],
   "source": [
    "human_bert = torch.tensor(human_bert)\n",
    "ai_bert = torch.tensor(ai_bert)\n",
    "human_gpt = torch.tensor(human_gpt).reshape([bert_min_length, 1, 768])\n",
    "ai_gpt = torch.tensor(ai_gpt).reshape([bert_min_length, 1, 768])\n",
    "human_flan = torch.tensor(human_flan).reshape([bert_min_length, 1, 4096])\n",
    "ai_flan = torch.tensor(ai_flan).reshape([bert_min_length, 1, 4096])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2278, 1, 1024]) torch.Size([2278, 1, 1024]) torch.Size([2278, 1, 768]) torch.Size([2278, 1, 768]) torch.Size([2278, 1, 4096]) torch.Size([2278, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(human_bert.shape, ai_bert.shape, human_gpt.shape, ai_gpt.shape, human_flan.shape, ai_flan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_bert = human_bert.view(bert_min_length, 16,64)\n",
    "human_gpt = human_gpt.view(bert_min_length, 12,64)\n",
    "human_flan = human_flan.view(bert_min_length, 64,64)\n",
    "\n",
    "ai_bert = ai_bert.view(bert_min_length, 16,64)\n",
    "ai_gpt = ai_gpt.view(bert_min_length, 12,64)\n",
    "ai_flan = ai_flan.view(bert_min_length, 64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2278, 16, 64]) torch.Size([2278, 16, 64]) torch.Size([2278, 12, 64]) torch.Size([2278, 12, 64]) torch.Size([2278, 64, 64]) torch.Size([2278, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(human_bert.shape, ai_bert.shape, human_gpt.shape, ai_gpt.shape, human_flan.shape, ai_flan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = torch.cat([human_bert, human_gpt, human_flan], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = torch.cat([ai_bert, ai_gpt, ai_flan], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = torch.cat((human, ai), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4556, 92, 64])\n"
     ]
    }
   ],
   "source": [
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros((bert_min_length))\n",
    "ones_tensor = torch.ones((bert_min_length))\n",
    "\n",
    "# Concatenate the tensors along the first dimension\n",
    "labels = torch.cat((zeros_tensor, ones_tensor), dim=0)\n",
    "\n",
    "# Display the result tensor\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4556, 92, 64])\n"
     ]
    }
   ],
   "source": [
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test_size = 0.2\n",
    "dataset = TensorDataset(embeds, labels)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=test_size, random_state=42)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader for training set\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 92, 64])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GPT_CNN2D(nn.Module):\n",
    "    def __init__(self, embedding_model):\n",
    "        super(GPT_CNN2D, self).__init__()\n",
    "        self.em_model = embedding_model\n",
    "        if embedding_model == \"gpt\":\n",
    "            self.conv1 = nn.Conv2d(1, 64, kernel_size=5, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.fc1 = nn.Linear(1056, 128)\n",
    "            self.fc2 = nn.Linear(128, 2)\n",
    "            self.relu = nn.ReLU()\n",
    "            # self.sigmoid = nn.Sigmoid()\n",
    "        elif embedding_model == \"mistral\" or embedding_model == \"flan\":\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=8, padding=1, stride = 2)\n",
    "            self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=1)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=3)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.bn3 = nn.BatchNorm2d(128)\n",
    "            self.flatten = nn.Flatten()            \n",
    "            # self.fc1 = nn.Linear(1152, 128)\n",
    "            self.fc1 = nn.Linear(512, 2)\n",
    "            self.relu = nn.ReLU()\n",
    "            # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        elif embedding_model == \"llama\":\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=8, padding=1, stride = 2)\n",
    "            self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=1)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=3)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "            self.bn3 = nn.BatchNorm2d(128)\n",
    "            self.flatten = nn.Flatten()            \n",
    "            # self.fc1 = nn.Linear(1152, 128)\n",
    "            self.fc1 = nn.Linear(512, 2)\n",
    "            self.relu = nn.ReLU()\n",
    "            # self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        elif embedding_model == \"fusion\":\n",
    "            self.conv1 = nn.Conv2d(1, 128, kernel_size=8, padding=1, stride = 2)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv2 = nn.Conv2d(128, 64, kernel_size=5, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.flatten = nn.Flatten()            \n",
    "            # self.fc1 = nn.Linear(96, 2)\n",
    "            self.fc1 = nn.Linear(64, 2)\n",
    "            # self.fc2 = nn.Linear(128, 2)\n",
    "            self.relu = nn.ReLU()\n",
    "            # self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        elif embedding_model == \"fusion3\":\n",
    "            self.conv1 = nn.Conv2d(1, 128, kernel_size=8, padding=1, stride = 2)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv2 = nn.Conv2d(128, 64, kernel_size=5, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.flatten = nn.Flatten() \n",
    "            self.fc1 = nn.Linear(480, 2)\n",
    "            # self.fc1 = nn.Linear(448, 2)\n",
    "            self.relu = nn.ReLU()\n",
    "            # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        elif embedding_model == \"fusion4\":\n",
    "            self.conv1 = nn.Conv2d(1, 128, kernel_size=8, padding=1, stride = 2)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv2 = nn.Conv2d(128, 64, kernel_size=5, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "            self.flatten = nn.Flatten() \n",
    "            self.fc1 = nn.Linear(896, 2)\n",
    "            # self.fc1 = nn.Linear(448, 2)\n",
    "            self.relu = nn.ReLU()\n",
    "            # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.em_model == \"gpt\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.flatten(x)\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            # x = self.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "        elif self.em_model == \"mistral\" or self.em_model == \"flan\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool3(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.flatten(x)\n",
    "            # x = self.relu(self.fc1(x))\n",
    "            x = self.fc1(x)\n",
    "            # x = self.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "        \n",
    "        elif self.em_model == \"llama\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool3(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.flatten(x)\n",
    "            # x = self.relu(self.fc1(x))\n",
    "            x = self.fc1(x)\n",
    "            # x = self.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "        elif self.em_model == \"fusion\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.flatten(x)\n",
    "            # x = self.relu(self.fc1(x))\n",
    "            x = self.fc1(x)\n",
    "            # x = self.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "        \n",
    "        elif self.em_model == \"fusion3\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.flatten(x)\n",
    "            # x = self.relu(self.fc1(x))\n",
    "            x = self.fc1(x)\n",
    "            # x = self.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "        elif self.em_model == \"fusion4\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.flatten(x)\n",
    "            # x = self.relu(self.fc1(x))\n",
    "            x = self.fc1(x)\n",
    "            # x = self.sigmoid(self.fc2(x))\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7495\n",
      "Validation Accuracy: 0.6963\n",
      "TP: 334, FP: 172, TN: 301, FN: 105\n",
      "Epoch [2/100], Loss: 0.6567\n",
      "Validation Accuracy: 0.7719\n",
      "TP: 285, FP: 54, TN: 419, FN: 154\n",
      "Epoch [3/100], Loss: 0.4100\n",
      "Validation Accuracy: 0.8761\n",
      "TP: 390, FP: 64, TN: 409, FN: 49\n",
      "Epoch [4/100], Loss: 0.2422\n",
      "Validation Accuracy: 0.9254\n",
      "TP: 409, FP: 38, TN: 435, FN: 30\n",
      "Epoch [5/100], Loss: 0.1626\n",
      "Validation Accuracy: 0.9342\n",
      "TP: 419, FP: 40, TN: 433, FN: 20\n",
      "Epoch [6/100], Loss: 0.1050\n",
      "Validation Accuracy: 0.9507\n",
      "TP: 424, FP: 30, TN: 443, FN: 15\n",
      "Epoch [7/100], Loss: 0.0733\n",
      "Validation Accuracy: 0.9200\n",
      "TP: 434, FP: 68, TN: 405, FN: 5\n",
      "Epoch [8/100], Loss: 0.0598\n",
      "Validation Accuracy: 0.9496\n",
      "TP: 432, FP: 39, TN: 434, FN: 7\n",
      "Epoch [9/100], Loss: 0.0347\n",
      "Validation Accuracy: 0.9649\n",
      "TP: 423, FP: 16, TN: 457, FN: 16\n",
      "Epoch [10/100], Loss: 0.0301\n",
      "Validation Accuracy: 0.9572\n",
      "TP: 428, FP: 28, TN: 445, FN: 11\n",
      "Epoch [11/100], Loss: 0.0173\n",
      "Validation Accuracy: 0.9627\n",
      "TP: 411, FP: 6, TN: 467, FN: 28\n",
      "Epoch [12/100], Loss: 0.0132\n",
      "Validation Accuracy: 0.9550\n",
      "TP: 433, FP: 35, TN: 438, FN: 6\n",
      "Epoch [13/100], Loss: 0.0077\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 426, FP: 16, TN: 457, FN: 13\n",
      "Epoch [14/100], Loss: 0.0075\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 423, FP: 9, TN: 464, FN: 16\n",
      "Epoch [15/100], Loss: 0.0027\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 429, FP: 16, TN: 457, FN: 10\n",
      "Epoch [16/100], Loss: 0.0019\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 424, FP: 12, TN: 461, FN: 15\n",
      "Epoch [17/100], Loss: 0.0015\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 425, FP: 13, TN: 460, FN: 14\n",
      "Epoch [18/100], Loss: 0.0011\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 426, FP: 14, TN: 459, FN: 13\n",
      "Epoch [19/100], Loss: 0.0010\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 430, FP: 16, TN: 457, FN: 9\n",
      "Epoch [20/100], Loss: 0.0008\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [21/100], Loss: 0.0007\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 430, FP: 16, TN: 457, FN: 9\n",
      "Epoch [22/100], Loss: 0.0006\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 426, FP: 15, TN: 458, FN: 13\n",
      "Epoch [23/100], Loss: 0.0005\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [24/100], Loss: 0.0005\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [25/100], Loss: 0.0004\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 427, FP: 15, TN: 458, FN: 12\n",
      "Epoch [26/100], Loss: 0.0003\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 426, FP: 13, TN: 460, FN: 13\n",
      "Epoch [27/100], Loss: 0.0003\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 427, FP: 14, TN: 459, FN: 12\n",
      "Epoch [28/100], Loss: 0.0003\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [29/100], Loss: 0.0002\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [30/100], Loss: 0.0002\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 425, FP: 15, TN: 458, FN: 14\n",
      "Epoch [31/100], Loss: 0.0002\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 426, FP: 13, TN: 460, FN: 13\n",
      "Epoch [32/100], Loss: 0.0002\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 425, FP: 13, TN: 460, FN: 14\n",
      "Epoch [33/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [34/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 425, FP: 13, TN: 460, FN: 14\n",
      "Epoch [35/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 426, FP: 14, TN: 459, FN: 13\n",
      "Epoch [36/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 427, FP: 15, TN: 458, FN: 12\n",
      "Epoch [37/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 425, FP: 13, TN: 460, FN: 14\n",
      "Epoch [38/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [39/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [40/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 424, FP: 12, TN: 461, FN: 15\n",
      "Epoch [41/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 429, FP: 15, TN: 458, FN: 10\n",
      "Epoch [42/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [43/100], Loss: 0.0001\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [44/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [45/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [46/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 429, FP: 15, TN: 458, FN: 10\n",
      "Epoch [47/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9671\n",
      "TP: 424, FP: 15, TN: 458, FN: 15\n",
      "Epoch [48/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 427, FP: 15, TN: 458, FN: 12\n",
      "Epoch [49/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 429, FP: 15, TN: 458, FN: 10\n",
      "Epoch [50/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9671\n",
      "TP: 424, FP: 15, TN: 458, FN: 15\n",
      "Epoch [51/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 429, FP: 15, TN: 458, FN: 10\n",
      "Epoch [52/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [53/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 429, FP: 15, TN: 458, FN: 10\n",
      "Epoch [54/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 424, FP: 14, TN: 459, FN: 15\n",
      "Epoch [55/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 424, FP: 14, TN: 459, FN: 15\n",
      "Epoch [56/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 425, FP: 15, TN: 458, FN: 14\n",
      "Epoch [57/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 424, FP: 14, TN: 459, FN: 15\n",
      "Epoch [58/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 424, FP: 12, TN: 461, FN: 15\n",
      "Epoch [59/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [60/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [61/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 425, FP: 15, TN: 458, FN: 14\n",
      "Epoch [62/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [63/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9726\n",
      "TP: 429, FP: 15, TN: 458, FN: 10\n",
      "Epoch [64/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [65/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [66/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 424, FP: 14, TN: 459, FN: 15\n",
      "Epoch [67/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 427, FP: 15, TN: 458, FN: 12\n",
      "Epoch [68/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [69/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 426, FP: 14, TN: 459, FN: 13\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [71/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [72/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [73/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 427, FP: 14, TN: 459, FN: 12\n",
      "Epoch [74/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 424, FP: 14, TN: 459, FN: 15\n",
      "Epoch [75/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 428, FP: 15, TN: 458, FN: 11\n",
      "Epoch [76/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 424, FP: 14, TN: 459, FN: 15\n",
      "Epoch [77/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [78/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [79/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [81/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 427, FP: 14, TN: 459, FN: 12\n",
      "Epoch [82/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [83/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9715\n",
      "TP: 427, FP: 14, TN: 459, FN: 12\n",
      "Epoch [84/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9682\n",
      "TP: 424, FP: 14, TN: 459, FN: 15\n",
      "Epoch [85/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [86/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [87/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [88/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 425, FP: 13, TN: 460, FN: 14\n",
      "Epoch [89/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 426, FP: 14, TN: 459, FN: 13\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 426, FP: 14, TN: 459, FN: 13\n",
      "Epoch [91/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 426, FP: 14, TN: 459, FN: 13\n",
      "Epoch [92/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [93/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 425, FP: 13, TN: 460, FN: 14\n",
      "Epoch [94/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [95/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 426, FP: 14, TN: 459, FN: 13\n",
      "Epoch [96/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9704\n",
      "TP: 425, FP: 13, TN: 460, FN: 14\n",
      "Epoch [97/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [98/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n",
      "Epoch [99/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 424, FP: 13, TN: 460, FN: 15\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Validation Accuracy: 0.9693\n",
      "TP: 425, FP: 14, TN: 459, FN: 14\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GPT_CNN2D(embedding_model = \"fusion3\").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "max_val_accuracy = 0\n",
    "# Step 5: Training Loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        #print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            TP += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            FP += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            TN += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "            FN += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "            total += labels.size(0)\n",
    "            #print(labels, predicted)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = correct / total\n",
    "    if max_val_accuracy<val_accuracy:\n",
    "        max_TP = TP\n",
    "        max_FP = FP\n",
    "        max_TN = TN\n",
    "        max_FN = FN\n",
    "    max_val_accuracy = max(max_val_accuracy, val_accuracy)\n",
    "    \n",
    "    \n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Validation Accuracy:  0.973\n",
      "TP:  423\n",
      "FP:  9\n",
      "TN:  464\n",
      "FN:  16\n",
      "Matthews Correlation Coefficient (MCC): 0.945\n",
      "True Positive Rate (TPR): 0.964\n",
      "False Positive Rate (FPR): 0.019\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum Validation Accuracy:  {max_val_accuracy:.3f}\")\n",
    "print(\"TP: \", max_TP)\n",
    "print(\"FP: \", max_FP)\n",
    "print(\"TN: \", max_TN)\n",
    "print(\"FN: \", max_FN)\n",
    "\n",
    "import math\n",
    "\n",
    "MCC = (max_TP * max_TN - max_FP * max_FN) / math.sqrt((max_TP + max_FP) * (max_TP + max_FN) * (max_TN + max_FP) * (max_TN + max_FN))\n",
    "\n",
    "print(f'Matthews Correlation Coefficient (MCC): {MCC:.3f}')\n",
    "\n",
    "TPR = max_TP / (max_TP + max_FN)\n",
    "FPR = max_FP / (max_FP + max_TN)\n",
    "\n",
    "print(f'True Positive Rate (TPR): {TPR:.3f}')\n",
    "print(f'False Positive Rate (FPR): {FPR:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
