{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4aaf1adfb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "# Load the model\n",
    "model_name = \"roberta-large\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/research-abstracts-labeled.csv')\n",
    "gpt = df[df['label'] == 1]\n",
    "human = df[df['label'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Mean pooling of token embeddings\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = last_hidden_states[:,0,:]\n",
    "    return embeddings.numpy()\n",
    "import numpy as np\n",
    "def remove_outliers(embeddings):\n",
    "        # Calculate the mode of the embeddings\n",
    "        mode_val = np.mean(embeddings[0], axis=None)\n",
    "        \n",
    "        # Replace outliers with the mode value\n",
    "        embeddings[np.abs(embeddings - mode_val) > 2 * np.std(embeddings)] = mode_val\n",
    "        \n",
    "        return embeddings\n",
    "def min_max_normalize(embeddings):\n",
    "    # Find the minimum and maximum values in the embeddings\n",
    "    min_val = np.min(embeddings)\n",
    "    max_val = np.max(embeddings)\n",
    "    \n",
    "    # Normalize the embeddings to range [0, 255]\n",
    "    normalized_embeddings = 255 * (embeddings - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_embeddings.astype(np.uint8)  # Convert to uint8 for integer values between 0 and 255\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    # Reshape the embeddings to 3D array\n",
    "    return embeddings.reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_915780/2595106749.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gpt['embeddings'] = gpt['text'].apply(generate_bert_embeddings)\n",
      "/tmp/ipykernel_915780/2595106749.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gpt['normalized_embeddings'] = gpt['embeddings'].apply(remove_outliers)\n",
      "/tmp/ipykernel_915780/2595106749.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gpt['normalized_embeddings1'] = gpt['normalized_embeddings'].apply(min_max_normalize)\n",
      "/tmp/ipykernel_915780/2595106749.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gpt['reshaped_embeddings'] = gpt['normalized_embeddings1'].apply(reshape_embeddings)\n"
     ]
    }
   ],
   "source": [
    "gpt['embeddings'] = gpt['text'].apply(generate_bert_embeddings)\n",
    "gpt['normalized_embeddings'] = gpt['embeddings'].apply(remove_outliers)\n",
    "gpt['normalized_embeddings1'] = gpt['normalized_embeddings'].apply(min_max_normalize)\n",
    "gpt['reshaped_embeddings'] = gpt['normalized_embeddings1'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embeddings = gpt['embeddings'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/gpt_embeddings_research.npy', 'wb') as f:\n",
    "    #for i in range(len(gpt['embeddings'])):\n",
    "    np.save(f, gpt_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_915780/3091784679.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  human['embeddings'] = human['text'].apply(generate_bert_embeddings)\n",
      "/tmp/ipykernel_915780/3091784679.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  human['normalized_embeddings'] = human['embeddings'].apply(remove_outliers)\n",
      "/tmp/ipykernel_915780/3091784679.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  human['normalized_embeddings1'] = human['normalized_embeddings'].apply(min_max_normalize)\n",
      "/tmp/ipykernel_915780/3091784679.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  human['reshaped_embeddings'] = human['normalized_embeddings1'].apply(reshape_embeddings)\n"
     ]
    }
   ],
   "source": [
    "human['embeddings'] = human['text'].apply(generate_bert_embeddings)\n",
    "human['normalized_embeddings'] = human['embeddings'].apply(remove_outliers)\n",
    "human['normalized_embeddings1'] = human['normalized_embeddings'].apply(min_max_normalize)\n",
    "human['reshaped_embeddings'] = human['normalized_embeddings1'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_embeddings = human['embeddings'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/human_embeddings_research.npy', 'wb') as f:\n",
    "    #for i in range(len(gpt['embeddings'])):\n",
    "    np.save(f, human_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
