{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "# Load the model\n",
    "model_name = \"roberta-large\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/wiki-labeled.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Scobie</td>\n",
       "      <td>0</td>\n",
       "      <td>James Scobie (29 November 1826 – 7 October 185...</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Scobie</td>\n",
       "      <td>1</td>\n",
       "      <td>James Scobie (29 November 1826 – 7 October 189...</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dagliç sheep</td>\n",
       "      <td>0</td>\n",
       "      <td>The Dagliç is a breed of sheep found primarily...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dagliç sheep</td>\n",
       "      <td>1</td>\n",
       "      <td>The Dagliç is a breed of sheep that is found i...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamdard India</td>\n",
       "      <td>0</td>\n",
       "      <td>Hamdard Laboratories (India), is a Unani pharm...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title  label                                               text  \\\n",
       "0   James Scobie      0  James Scobie (29 November 1826 – 7 October 185...   \n",
       "1   James Scobie      1  James Scobie (29 November 1826 – 7 October 189...   \n",
       "2   Dagliç sheep      0  The Dagliç is a breed of sheep found primarily...   \n",
       "3   Dagliç sheep      1  The Dagliç is a breed of sheep that is found i...   \n",
       "4  Hamdard India      0  Hamdard Laboratories (India), is a Unani pharm...   \n",
       "\n",
       "   word_count  \n",
       "0         175  \n",
       "1         242  \n",
       "2         152  \n",
       "3          33  \n",
       "4         160  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = df[df['label'] == 0]\n",
    "human = df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(len(gpt))\n",
    "print(len(human))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = gpt.sample(n=15000)\n",
    "human = human.sample(n=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "print(len(gpt))\n",
    "print(len(human))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Mean pooling of token embeddings\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = last_hidden_states[:,0,:]\n",
    "    return embeddings.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def remove_outliers(embeddings):\n",
    "        # Calculate the mode of the embeddings\n",
    "        mode_val = np.mean(embeddings[0], axis=None)\n",
    "        \n",
    "        # Replace outliers with the mode value\n",
    "        embeddings[np.abs(embeddings - mode_val) > 2 * np.std(embeddings)] = mode_val\n",
    "        \n",
    "        return embeddings\n",
    "def min_max_normalize(embeddings):\n",
    "    # Find the minimum and maximum values in the embeddings\n",
    "    min_val = np.min(embeddings)\n",
    "    max_val = np.max(embeddings)\n",
    "    \n",
    "    # Normalize the embeddings to range [0, 255]\n",
    "    normalized_embeddings = 255 * (embeddings - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_embeddings.astype(np.uint8)  # Convert to uint8 for integer values between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_embeddings(embeddings):\n",
    "    # Reshape the embeddings to 3D array\n",
    "    return embeddings.reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt['embeddings'] = gpt['text'].apply(generate_bert_embeddings)\n",
    "gpt['normalized_embeddings'] = gpt['embeddings'].apply(remove_outliers)\n",
    "gpt['normalized_embeddings1'] = gpt['normalized_embeddings'].apply(min_max_normalize)\n",
    "gpt['reshaped_embeddings'] = gpt['normalized_embeddings1'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embeddings = gpt['embeddings'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/gpt_embeddings_wiki.npy', 'wb') as f:\n",
    "    #for i in range(len(gpt['embeddings'])):\n",
    "    np.save(f, gpt_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embed = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/gpt_embeddings_wiki.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embed1 = list(gpt_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16914399 -0.27530515 -0.16552505 ...  0.3751053  -0.46027824\n",
      "   0.38559914]]\n"
     ]
    }
   ],
   "source": [
    "print((gpt_embed[14999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(gpt_embed.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_606165/654233572.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  gpt_embed_tensor = torch.tensor(gpt_embed1)\n"
     ]
    }
   ],
   "source": [
    "gpt_embed_tensor = torch.tensor(gpt_embed1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1691, -0.2753, -0.1655,  ...,  0.3751, -0.4603,  0.3856]])\n"
     ]
    }
   ],
   "source": [
    "print(gpt_embed_tensor[14999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16914399 -0.27530515 -0.16552505 ...  0.3751053  -0.46027824\n",
      "   0.38559914]]\n"
     ]
    }
   ],
   "source": [
    "print(gpt['embeddings'].iloc[14999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "human['embeddings'] = human['text'].apply(generate_bert_embeddings)\n",
    "human['normalized_embeddings'] = human['embeddings'].apply(remove_outliers)\n",
    "human['normalized_embeddings1'] = human['normalized_embeddings'].apply(min_max_normalize)\n",
    "human['reshaped_embeddings'] = human['normalized_embeddings1'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_embeddings = human['embeddings'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/human_embeddings_wiki.npy', 'wb') as f:\n",
    "    #for i in range(len(gpt['embeddings'])):\n",
    "    np.save(f, human_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'numpy.ndarray'>]\n"
     ]
    }
   ],
   "source": [
    "print(gpt['reshaped_embeddings'].apply(type).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(gpt['reshaped_embeddings'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.to_csv('../Data/gpt_wiki_embeddings1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human.to_csv('../Data/human_wiki_embeddings1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../Data/gpt_wiki_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mgpt\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreshaped_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(gpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreshaped_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Assuming grayscale image\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Hide axes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(gpt['reshaped_embeddings'])):\n",
    "    plt.imshow(gpt['reshaped_embeddings'].iloc[i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/output/Research_GPT/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(human['reshaped_embeddings'])):\n",
    "    plt.imshow(human['reshaped_embeddings'].iloc[i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/output/Human2/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_text = \"\"\"\" ﻿The argument states that restoring the time spent on weather and local news to its formal levels, would attract viewers and avoid losing any further advertising revenue. Though the argument seems reasonable at first by comparing information on a superficial basis, it does fail to account for a lot of factors and relies on a certain number of assumptions. However, proving these assumptions faulty might result in making this argument meaningless.\n",
    "\n",
    "Firstly, it is clear from the argument that the programs are intended to show late at night. The number of viewers at night is most probably be less than during the day. The details of the number of viewers who are focused on weather and local news, late at night have not been discussed, which in turn could not give us at least an approximate amount of the viewers lost. If any survey is conducted on the number and details of people watching a late-night news program, then it might help in determining the actual loss of viewers occurred due to this.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embed = generate_bert_embeddings(gpt_text)\n",
    "gpt_embed1 = remove_outliers(gpt_embed)\n",
    "gpt_embed2 = min_max_normalize(gpt_embed1)\n",
    "gpt_embed3 = reshape_embeddings(gpt_embed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gpt_embed3, cmap='gray')  # Assuming grayscale image\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/sample_human.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
