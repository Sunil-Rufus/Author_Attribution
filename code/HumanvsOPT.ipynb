{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "torch.manual_seed(42)\n",
    "\n",
    "df = pd.read_csv('/home/csgrad/kaushik3/LLM/Kaggle_63LLMs/OPT/human_opt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "# Load the model\n",
    "model_name = \"roberta-large\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human       278018\n",
       "OPT-1.3B     14783\n",
       "OPT-30B      14539\n",
       "OPT-2.7B      7292\n",
       "OPT-6.7B      7143\n",
       "OPT-125M      7048\n",
       "OPT-350M      7033\n",
       "OPT-13B       6410\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>label_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huge amounts of digital videos are being produ...</td>\n",
       "      <td>OPT-30B</td>\n",
       "      <td>0</td>\n",
       "      <td>719</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The smell of burned hair acummulated in Gordon...</td>\n",
       "      <td>OPT-30B</td>\n",
       "      <td>0</td>\n",
       "      <td>797</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If it is too warm, the flavors will not taste ...</td>\n",
       "      <td>OPT-125M</td>\n",
       "      <td>0</td>\n",
       "      <td>1181</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Diane never wins anything. She was feeling luc...</td>\n",
       "      <td>OPT-13B</td>\n",
       "      <td>0</td>\n",
       "      <td>6312</td>\n",
       "      <td>834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Robertson (The Canadian): High levels of torqu...</td>\n",
       "      <td>OPT-30B</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text    source  prompt_id  \\\n",
       "2   Huge amounts of digital videos are being produ...   OPT-30B          0   \n",
       "12  The smell of burned hair acummulated in Gordon...   OPT-30B          0   \n",
       "13  If it is too warm, the flavors will not taste ...  OPT-125M          0   \n",
       "21  Diane never wins anything. She was feeling luc...   OPT-13B          0   \n",
       "27  Robertson (The Canadian): High levels of torqu...   OPT-30B          0   \n",
       "\n",
       "    text_length  word_count  label_map  \n",
       "2           719         109          1  \n",
       "12          797         139          1  \n",
       "13         1181         211          1  \n",
       "21         6312         834          1  \n",
       "27          329          58          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI = df[df['source'].str.startswith('OPT')]\n",
    "AI.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278018\n"
     ]
    }
   ],
   "source": [
    "Human = df[df['source'] == 'Human']\n",
    "print(len(Human))\n",
    "Human = Human[:len(AI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64248\n",
      "64248\n"
     ]
    }
   ],
   "source": [
    "print(len(Human))\n",
    "print(len(AI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Mean pooling of token embeddings\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = last_hidden_states[:,0,:]\n",
    "    return embeddings.numpy()\n",
    "import numpy as np\n",
    "def remove_outliers(embeddings):\n",
    "        # Calculate the mode of the embeddings\n",
    "        mode_val = np.mean(embeddings[0], axis=None)\n",
    "        \n",
    "        # Replace outliers with the mode value\n",
    "        embeddings[np.abs(embeddings - mode_val) > 2 * np.std(embeddings)] = mode_val\n",
    "        \n",
    "        return embeddings\n",
    "def min_max_normalize(embeddings):\n",
    "    # Find the minimum and maximum values in the embeddings\n",
    "    min_val = np.min(embeddings)\n",
    "    max_val = np.max(embeddings)\n",
    "    \n",
    "    # Normalize the embeddings to range [0, 255]\n",
    "    normalized_embeddings = 255 * (embeddings - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_embeddings.astype(np.uint8)  # Convert to uint8 for integer values between 0 and 255\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    # Reshape the embeddings to 3D array\n",
    "    return embeddings.reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Human['embeddings'] = Human['text'].apply(generate_bert_embeddings)\n",
    "Human['embeddings1'] = Human['embeddings'].apply(remove_outliers)\n",
    "Human['normalized_embeddings'] = Human['embeddings1'].apply(min_max_normalize)\n",
    "Human['reshaped_embeddings'] = Human['normalized_embeddings'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1888842/1706120243.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['embeddings'] = AI['text'].apply(generate_bert_embeddings)\n",
      "/tmp/ipykernel_1888842/1706120243.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['embeddings1'] = AI['embeddings'].apply(remove_outliers)\n",
      "/tmp/ipykernel_1888842/1706120243.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['normalized_embeddings'] = AI['embeddings1'].apply(min_max_normalize)\n",
      "/tmp/ipykernel_1888842/1706120243.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['reshaped_embeddings'] = AI['normalized_embeddings'].apply(reshape_embeddings)\n"
     ]
    }
   ],
   "source": [
    "AI['embeddings'] = AI['text'].apply(generate_bert_embeddings)\n",
    "AI['embeddings1'] = AI['embeddings'].apply(remove_outliers)\n",
    "AI['normalized_embeddings'] = AI['embeddings1'].apply(min_max_normalize)\n",
    "AI['reshaped_embeddings'] = AI['normalized_embeddings'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_embeddings = AI['embeddings']\n",
    "\n",
    "with open('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/opt_embeddings.npy', 'wb') as f:\n",
    "    #for i in range(len(gpt['embeddings'])):\n",
    "    np.save(f, AI_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(AI['reshaped_embeddings'])):\n",
    "    plt.imshow(AI['reshaped_embeddings'].iloc[i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/OPT/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "AI_embeddings = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/opt_embeddings.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(AI_embeddings)):\n",
    "    \n",
    "    AI_embeddings[i] = remove_outliers(AI_embeddings[i])\n",
    "    AI_embeddings[i] = min_max_normalize(AI_embeddings[i])\n",
    "    AI_embeddings[i] = reshape_embeddings(AI_embeddings[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(49192, len(AI_embeddings)):\n",
    "    plt.imshow(AI_embeddings[i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/OPT/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder: 64248\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/OPT'  # Replace with the actual folder path\n",
    "\n",
    "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "print(\"Number of files in the folder:\", file_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
