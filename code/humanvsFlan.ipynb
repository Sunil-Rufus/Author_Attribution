{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "torch.manual_seed(42)\n",
    "\n",
    "df = pd.read_csv('/home/csgrad/kaushik3/LLM/Kaggle_63LLMs/FLAN/human_flan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "# Load the model\n",
    "model_name = \"roberta-large\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human            278018\n",
       "Flan-T5-Base       7358\n",
       "Flan-T5-Large      7352\n",
       "Flan-T5-Small      7320\n",
       "Flan-T5-XXL        7305\n",
       "Flan-T5-XL         7243\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>label_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Apple announced updates to iOS, iPadOS, MacOS,...</td>\n",
       "      <td>Flan-T5-Base</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Then, select a bedtime that allows your child ...</td>\n",
       "      <td>Flan-T5-Large</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Overall...a sensational effort. From the atmos...</td>\n",
       "      <td>Flan-T5-XL</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Yes and no. Are they going to have to share th...</td>\n",
       "      <td>Flan-T5-XXL</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Here's an obscure one. List of US cities with ...</td>\n",
       "      <td>Flan-T5-XL</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text         source  \\\n",
       "23  Apple announced updates to iOS, iPadOS, MacOS,...   Flan-T5-Base   \n",
       "24  Then, select a bedtime that allows your child ...  Flan-T5-Large   \n",
       "46  Overall...a sensational effort. From the atmos...     Flan-T5-XL   \n",
       "51  Yes and no. Are they going to have to share th...    Flan-T5-XXL   \n",
       "55  Here's an obscure one. List of US cities with ...     Flan-T5-XL   \n",
       "\n",
       "    prompt_id  text_length  word_count  label_map  \n",
       "23          0          220          38          1  \n",
       "24          0          211          40          1  \n",
       "46          0          248          36          1  \n",
       "51          0          174          33          1  \n",
       "55          0          197          36          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI = df[df['source'].str.startswith('Flan')]\n",
    "AI.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Human = df[df['source'] == 'Human']\n",
    "Human = Human[:len(AI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36578\n",
      "36578\n"
     ]
    }
   ],
   "source": [
    "print(len(Human))\n",
    "print(len(AI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Mean pooling of token embeddings\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = last_hidden_states[:,0,:]\n",
    "    return embeddings.numpy()\n",
    "import numpy as np\n",
    "def remove_outliers(embeddings):\n",
    "        # Calculate the mode of the embeddings\n",
    "        mode_val = np.mean(embeddings[0], axis=None)\n",
    "        \n",
    "        # Replace outliers with the mode value\n",
    "        embeddings[np.abs(embeddings - mode_val) > 2 * np.std(embeddings)] = mode_val\n",
    "        \n",
    "        return embeddings\n",
    "def min_max_normalize(embeddings):\n",
    "    # Find the minimum and maximum values in the embeddings\n",
    "    min_val = np.min(embeddings)\n",
    "    max_val = np.max(embeddings)\n",
    "    \n",
    "    # Normalize the embeddings to range [0, 255]\n",
    "    normalized_embeddings = 255 * (embeddings - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_embeddings.astype(np.uint8)  # Convert to uint8 for integer values between 0 and 255\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    # Reshape the embeddings to 3D array\n",
    "    return embeddings.reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI['embeddings'] = AI['text'].apply(generate_bert_embeddings)\n",
    "AI['embeddings1'] = AI['embeddings'].apply(remove_outliers)\n",
    "AI['normalized_embeddings'] = AI['embeddings1'].apply(min_max_normalize)\n",
    "AI['reshaped_embeddings'] = AI['normalized_embeddings'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_embeddings = AI['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/flan_embeddings.npy', 'wb') as f:\n",
    "    #for i in range(len(gpt['embeddings'])):\n",
    "    np.save(f, AI_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "AI_embeddings = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/flan_embeddings.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(AI_embeddings)):\n",
    "    \n",
    "    AI_embeddings[i] = remove_outliers(AI_embeddings[i])\n",
    "    AI_embeddings[i] = min_max_normalize(AI_embeddings[i])\n",
    "    AI_embeddings[i] = reshape_embeddings(AI_embeddings[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36578,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_embeddings)\n",
    "AI_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(23475, len(AI_embeddings)):\n",
    "    plt.imshow(AI_embeddings[i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/Flan/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder: 36578\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/Flan/'  # Replace with the actual folder path\n",
    "\n",
    "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "print(\"Number of files in the folder:\", file_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
