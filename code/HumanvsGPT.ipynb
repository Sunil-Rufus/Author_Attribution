{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "torch.manual_seed(42)\n",
    "\n",
    "df = pd.read_csv('/home/csgrad/kaushik3/LLM/Kaggle_63LLMs/GPT/human_gpt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "# Load the model\n",
    "model_name = \"roberta-large\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human       278018\n",
       "GPT-3.5      41833\n",
       "GPT-4         7095\n",
       "GPT-J         6040\n",
       "GPT-NeoX      5451\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>label_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The legal implications of space law for extrat...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1845</td>\n",
       "      <td>5754</td>\n",
       "      <td>853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Role of Biomimicry in Sustainable Urban Wa...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>420</td>\n",
       "      <td>5645</td>\n",
       "      <td>770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Microplastics have become a major concern in r...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>747</td>\n",
       "      <td>3966</td>\n",
       "      <td>592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>As she was browsing through the clearance rack...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Art is an integral part of society, playing a ...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>4192</td>\n",
       "      <td>2752</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   source  prompt_id  \\\n",
       "2   The legal implications of space law for extrat...  GPT-3.5       1845   \n",
       "7   The Role of Biomimicry in Sustainable Urban Wa...  GPT-3.5        420   \n",
       "11  Microplastics have become a major concern in r...  GPT-3.5        747   \n",
       "21  As she was browsing through the clearance rack...  GPT-3.5          0   \n",
       "43  Art is an integral part of society, playing a ...  GPT-3.5       4192   \n",
       "\n",
       "    text_length  word_count  label_map  \n",
       "2          5754         853          1  \n",
       "7          5645         770          1  \n",
       "11         3966         592          1  \n",
       "21         1474         268          1  \n",
       "43         2752         415          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI = df[df['source'].str.startswith('GPT')]\n",
    "AI.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278018\n"
     ]
    }
   ],
   "source": [
    "Human = df[df['source'] == 'Human']\n",
    "print(len(Human))\n",
    "Human = Human[:len(AI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60419\n",
      "60419\n"
     ]
    }
   ],
   "source": [
    "print(len(Human))\n",
    "print(len(AI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Mean pooling of token embeddings\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = last_hidden_states[:,0,:]\n",
    "    return embeddings.numpy()\n",
    "import numpy as np\n",
    "def remove_outliers(embeddings):\n",
    "        # Calculate the mode of the embeddings\n",
    "        mode_val = np.mean(embeddings[0], axis=None)\n",
    "        \n",
    "        # Replace outliers with the mode value\n",
    "        embeddings[np.abs(embeddings - mode_val) > 2 * np.std(embeddings)] = mode_val\n",
    "        \n",
    "        return embeddings\n",
    "def min_max_normalize(embeddings):\n",
    "    # Find the minimum and maximum values in the embeddings\n",
    "    min_val = np.min(embeddings)\n",
    "    max_val = np.max(embeddings)\n",
    "    \n",
    "    # Normalize the embeddings to range [0, 255]\n",
    "    normalized_embeddings = 255 * (embeddings - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_embeddings.astype(np.uint8)  # Convert to uint8 for integer values between 0 and 255\n",
    "\n",
    "def reshape_embeddings(embeddings):\n",
    "    # Reshape the embeddings to 3D array\n",
    "    return embeddings.reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1645877/1706120243.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['embeddings'] = AI['text'].apply(generate_bert_embeddings)\n",
      "/tmp/ipykernel_1645877/1706120243.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['embeddings1'] = AI['embeddings'].apply(remove_outliers)\n",
      "/tmp/ipykernel_1645877/1706120243.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['normalized_embeddings'] = AI['embeddings1'].apply(min_max_normalize)\n",
      "/tmp/ipykernel_1645877/1706120243.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AI['reshaped_embeddings'] = AI['normalized_embeddings'].apply(reshape_embeddings)\n"
     ]
    }
   ],
   "source": [
    "AI['embeddings'] = AI['text'].apply(generate_bert_embeddings)\n",
    "AI['embeddings1'] = AI['embeddings'].apply(remove_outliers)\n",
    "AI['normalized_embeddings'] = AI['embeddings1'].apply(min_max_normalize)\n",
    "AI['reshaped_embeddings'] = AI['normalized_embeddings'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_embeddings = AI['embeddings']\n",
    "\n",
    "with open('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/gpt_embeddings.npy', 'wb') as f:\n",
    "    #for i in range(len(gpt['embeddings'])):\n",
    "    np.save(f, AI_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(AI['reshaped_embeddings'])):\n",
    "    plt.imshow(AI['reshaped_embeddings'].iloc[i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/GPT/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "AI_embeddings = np.load('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/embeddings/gpt_embeddings.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(AI_embeddings)):\n",
    "    \n",
    "    AI_embeddings[i] = remove_outliers(AI_embeddings[i])\n",
    "    AI_embeddings[i] = min_max_normalize(AI_embeddings[i])\n",
    "    AI_embeddings[i] = reshape_embeddings(AI_embeddings[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10720, len(AI_embeddings)):\n",
    "    plt.imshow(AI_embeddings[i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/GPT/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder: 60419\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/HumanvsLLM/GPT/'  # Replace with the actual folder path\n",
    "\n",
    "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "print(\"Number of files in the folder:\", file_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Human['embeddings'] = Human['text'].apply(generate_bert_embeddings)\n",
    "Human['embeddings1'] = Human['embeddings'].apply(remove_outliers)\n",
    "Human['normalized_embeddings'] = Human['embeddings1'].apply(min_max_normalize)\n",
    "Human['reshaped_embeddings'] = Human['normalized_embeddings'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
