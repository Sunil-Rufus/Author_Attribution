{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc68b1c5fb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "# Load the model\n",
    "model_name = \"roberta-large\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/wiki-labeled.csv')\n",
    "gpt = df[df['label'] == 0]\n",
    "human = df[df['label'] == 1]\n",
    "gpt = gpt.sample(n=150)\n",
    "human = human.sample(n=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Mean pooling of token embeddings\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = last_hidden_states[:,0,:]\n",
    "    return embeddings.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt['embeddings'] = gpt['text'].apply(generate_bert_embeddings)\n",
    "human['embeddings'] = human['text'].apply(generate_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels, 8, kernel_size=16, stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=8, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=8, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4, stride=2)\n",
    "\n",
    "        # self.conv3 = nn.Conv2d(4, 128, kernel_size=3, stride=1, padding=1)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(1920, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        # x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.relu5(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(1, 8, kernel_size=(16,), stride=(2,))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool1d(kernel_size=8, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(8, 16, kernel_size=(8,), stride=(1,))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=1920, out_features=512, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (relu5): ReLU()\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Define the model architecture (make sure it matches the architecture of the saved model)\n",
    "#model = models.resnet18()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(in_channels=1, num_classes=2).to(device)\n",
    "# Path to the saved model\n",
    "model_path = \"/home/csgrad/sunilruf/detect_llm/sunil_code/LLM/model/wiki_model_1D.pth\"\n",
    "\n",
    "# Load the saved model parameters into the model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Now the model is loaded and ready for inference or further training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embeds = torch.Tensor(gpt['embeddings'].tolist())\n",
    "human_embeds = torch.Tensor(human['embeddings'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_pred = []\n",
    "for embed in gpt_embeds:\n",
    "    embed = embed.unsqueeze(0).to(device)\n",
    "    #embed = embed.unsqueeze(0)\n",
    "    output = model(embed)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    #print(predicted.item())\n",
    "    gpt_pred.append(predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 150})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(gpt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_pred = []\n",
    "for embed in human_embeds:\n",
    "    embed = embed.unsqueeze(0).to(device)\n",
    "    #embed = embed.unsqueeze(0)\n",
    "    output = model(embed)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    #print(predicted.item())\n",
    "    human_pred.append(predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 150})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(human_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
